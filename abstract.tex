\begin{abstract}
In the last few years, there has been a tremendous increase in the use of big data. Most of this data is hard to understand because of its size and dimensions. The importance of this problem can be emphasized by the fact that Big Data Research and Development Initiative was announced by the United States administration in 2012 to address problems faced by the government. Various states and cities in the US gather spatial data about incidents like police calls for service.  

When we query large amounts of data, it may lead to a lot of questions. For example, why does a visualization of the data look different for one part of the data compared to another? This kind of problem can be solved by aggravation: tuples in the database which represents extreme values of our observations, and intervention: tuples in the database which introduce a large change in the observation when removed. We call the predicates which represent these tuples, explanations.

While aggravation and intervention are designed for non spatial data, we propose a new approach for explaining spatially heterogeneous data. Our approach expands on aggravation and intervention while using spatial partitioning/clustering to improve explanations for spatial data. Our proposed approach was evaluated against real-world taxi dataset as well as synthetic disease outbreak datasets. The approach was found to outperform aggravation in precision and recall while outperforming intervention in precision.
\end{abstract}